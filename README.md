# VidCap
Video Captioning Using BLIP model  
> [ðŸ“œpaper](https://arxiv.org/abs/2201.12086v2)  
> [ðŸ¤—HuggingFace](https://huggingface.co/Salesforce/blip-vqa-base)  
> [git](https://github.com/dino-chiio/blip-vqa-finetune/blob/main/finetuning.py)

## Process
1. Input video  
2. ```python main.py```  
3. Blip do caption every 15fps  
4. Save output to JSON  
  
  
<img src = "blip.png"  width="80%">  

## Output Example